# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from glob import glob  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒãƒƒãƒãƒ³ã‚°ã«ä½¿ç”¨
import streamlit as st  # ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
import pdfplumber  # PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from langchain.text_splitter import RecursiveCharacterTextSplitter  # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from langchain.vectorstores import Qdrant  # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’æ§‹ç¯‰ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from langchain.embeddings.openai import OpenAIEmbeddings  # OpenAIã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from langchain.chains import RetrievalQA  # è³ªå•å¿œç­”ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from langchain.chat_models import ChatOpenAI  # OpenAIã®ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from langchain.llms import OpenAI  # OpenAIã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from langchain.callbacks import get_openai_callback  # OpenAIã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å–å¾—ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from qdrant_client import QdrantClient  # Qdrantã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from qdrant_client.models import Distance, VectorParams  # Qdrantã®ãƒ™ã‚¯ãƒˆãƒ«è¨­å®š

# Qdrant ã®è¨­å®š
QDRANT_PATH = "./local_qdrant"  # ãƒ­ãƒ¼ã‚«ãƒ«Qdrantã®ãƒ‘ã‚¹
COLLECTION_NAME = "study_materials"  # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å

# ãƒšãƒ¼ã‚¸ã®åˆæœŸåŒ–
def init_page():
    st.set_page_config(
        page_title="Study Helper",  # ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
        page_icon="ğŸ“˜"  # ãƒšãƒ¼ã‚¸ã®ã‚¢ã‚¤ã‚³ãƒ³ã‚’è¨­å®š
    )
    st.sidebar.title("Navigation")  # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
    st.session_state.costs = []  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ã‚³ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆã‚’åˆæœŸåŒ–

# ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
def select_model():
    model = st.sidebar.radio("Choose a model:", ("GPT-3.5", "GPT-3.5-16k", "GPT-4", "GPT-4o"))  # ãƒ¢ãƒ‡ãƒ«é¸æŠã®ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³
    if model == "GPT-3.5":
        st.session_state.model_name = "gpt-3.5-turbo"  # GPT-3.5 ãƒ¢ãƒ‡ãƒ«åã‚’è¨­å®š
    elif model == "GPT-3.5-16k":
        st.session_state.model_name = "gpt-3.5-turbo-16k"  # GPT-3.5-16k ãƒ¢ãƒ‡ãƒ«åã‚’è¨­å®š
    elif model == "GPT-4":
        st.session_state.model_name = "gpt-4"  # GPT-4 ãƒ¢ãƒ‡ãƒ«åã‚’è¨­å®š
    else:
        st.session_state.model_name = "gpt-4o"  # GPT-4o ãƒ¢ãƒ‡ãƒ«åã‚’è¨­å®š

    st.session_state.max_token = OpenAI.modelname_to_contextsize(st.session_state.model_name) - 300  # æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨­å®š
    return ChatOpenAI(temperature=0, model_name=st.session_state.model_name)  # é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è¿”ã™

# PDF ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
def get_pdf_text(uploaded_file):
    with pdfplumber.open(uploaded_file) as pdf:
        text = ''  # ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆæœŸåŒ–
        for page in pdf.pages:
            text += page.extract_text() + '\n'  # å„ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦çµåˆ
    return text  # æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™

# ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã™ã‚‹é–¢æ•°
def split_text(text):
    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        model_name="text-embedding-ada-002",  # ä½¿ç”¨ã™ã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®š
        chunk_size=500,  # ãƒãƒ£ãƒ³ã‚¯ã®ã‚µã‚¤ã‚ºã‚’è¨­å®š
        chunk_overlap=0,  # ãƒãƒ£ãƒ³ã‚¯ã®é‡è¤‡ã‚’è¨­å®š
    )
    return text_splitter.split_text(text)  # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦è¿”ã™

# Qdrant ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°
def load_qdrant():
    client = QdrantClient(path=QDRANT_PATH)  # Qdrant ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    collections = client.get_collections().collections  # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒªã‚¹ãƒˆã‚’å–å¾—
    collection_names = [collection.name for collection in collections]  # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ

    if COLLECTION_NAME not in collection_names:
        client.create_collection(
            collection_name=COLLECTION_NAME,  # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚’æŒ‡å®š
            vectors_config=VectorParams(size=1536, distance=Distance.COSINE),  # ãƒ™ã‚¯ãƒˆãƒ«ã®è¨­å®šã‚’æŒ‡å®š
        )
        print('collection created')  # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒä½œæˆã•ã‚ŒãŸã“ã¨ã‚’è¡¨ç¤º

    return Qdrant(
        client=client,  # Qdrant ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è¨­å®š
        collection_name=COLLECTION_NAME,  # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚’è¨­å®š
        embeddings=OpenAIEmbeddings()  # ä½¿ç”¨ã™ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š
    )

# ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’æ§‹ç¯‰ã™ã‚‹é–¢æ•°
def build_vector_store(pdf_text):
    qdrant = load_qdrant()  # Qdrant ã‚’ãƒ­ãƒ¼ãƒ‰
    qdrant.add_texts(pdf_text)  # ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ ã—ã¦ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’æ§‹ç¯‰

# è³ªå•å¿œç­”ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹é–¢æ•°
def build_qa_model(llm):
    qdrant = load_qdrant()  # Qdrant ã‚’ãƒ­ãƒ¼ãƒ‰
    retriever = qdrant.as_retriever(
        search_type="similarity",  # é¡ä¼¼æ€§æ¤œç´¢ã‚’è¨­å®š
        search_kwargs={"k":10}  # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
    )
    return RetrievalQA.from_chain_type(
        llm=llm,  # ä½¿ç”¨ã™ã‚‹LLMã‚’è¨­å®š
        chain_type="stuff",  # ãƒã‚§ãƒ¼ãƒ³ã®ã‚¿ã‚¤ãƒ—ã‚’è¨­å®š
        retriever=retriever,  # ãƒ¬ãƒˆãƒªãƒãƒ¼ã‚’è¨­å®š
        return_source_documents=True,  # ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿”ã™è¨­å®š
        verbose=True  # è©³ç´°å‡ºåŠ›ã‚’è¨­å®š
    )

# PDF ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®æ§‹ç¯‰ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
def page_pdf_upload_and_build_vector_db():
    st.title("PDF Upload")  # ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
    container = st.container()  # ã‚³ãƒ³ãƒ†ãƒŠã‚’ä½œæˆ
    with container:
        uploaded_file = st.file_uploader(label='Upload your study PDF hereğŸ“š', type='pdf')  # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆ
        if uploaded_file:
            with st.spinner("Extracting text from PDF..."):  # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºä¸­ã®ã‚¹ãƒ”ãƒŠãƒ¼ã‚’è¡¨ç¤º
                pdf_text = get_pdf_text(uploaded_file)  # PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
                st.write("Extracted Text:")  # æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ãƒ©ãƒ™ãƒ«ã‚’è¡¨ç¤º
                st.write(pdf_text)  # æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
                pdf_chunks = split_text(pdf_text)  # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
            with st.spinner("Building vector store..."):  # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢æ§‹ç¯‰ä¸­ã®ã‚¹ãƒ”ãƒŠãƒ¼ã‚’è¡¨ç¤º
                build_vector_store(pdf_chunks)  # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’æ§‹ç¯‰
            st.success("PDF uploaded and processed successfully!")  # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º

# å•é¡Œã‚’ç”Ÿæˆã—ã€æ­£èª¤åˆ¤å®šã‚’è¡Œã†é–¢æ•°
def generate_question_and_check_answer(qa, query, user_answer):
    with get_openai_callback() as cb:  # OpenAIã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¨­å®š
        response = qa(query)  # è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’å–å¾—
    correct_answer = response["result"]  # å›ç­”ã‚’å–å¾—
    is_correct = user_answer.lower() in correct_answer.lower()  # æ­£èª¤åˆ¤å®šã‚’è¡Œã†
    return correct_answer, is_correct, cb.total_cost  # å›ç­”ã€æ­£èª¤åˆ¤å®šçµæœã€ã‚³ã‚¹ãƒˆã‚’è¿”ã™

# å•é¡Œã‚’å‡ºé¡Œã™ã‚‹ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
def page_ask_my_pdf():
    st.title("Study Questions")  # ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
    llm = select_model()  # ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
    container = st.container()  # ã‚³ãƒ³ãƒ†ãƒŠã‚’ä½œæˆ
    response_container = st.container()  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚³ãƒ³ãƒ†ãƒŠã‚’ä½œæˆ
    with container:
        query = st.text_input("Enter your question: ", key="input")  # ã‚¯ã‚¨ãƒªã®å…¥åŠ›æ¬„ã‚’ä½œæˆ
        user_answer = st.text_input("Enter your answer: ", key="answer")  # è§£ç­”ã®å…¥åŠ›æ¬„ã‚’ä½œæˆ
        if query and user_answer:
            qa = build_qa_model(llm)  # è³ªå•å¿œç­”ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰
            if qa:
                with st.spinner("Checking your answer..."):  # å›ç­”ç¢ºèªä¸­ã®ã‚¹ãƒ”ãƒŠãƒ¼ã‚’è¡¨ç¤º
                    correct_answer, is_correct, cost = generate_question_and_check_answer(qa, query, user_answer)  # æ­£èª¤åˆ¤å®šã‚’è¡Œã†
                st.session_state.costs.append(cost)  # ã‚³ã‚¹ãƒˆã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«è¿½åŠ 
                if is_correct:
                    st.success(f"Correct! The answer is: {correct_answer}")  # æ­£è§£ã®å ´åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
                else:
                    st.error(f"Incorrect. The correct answer is: {correct_answer}")  # ä¸æ­£è§£ã®å ´åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
                st.markdown(f"## Explanation")  # è§£èª¬ã®ãƒ©ãƒ™ãƒ«ã‚’è¡¨ç¤º
                st.write(correct_answer)  # è§£èª¬ã‚’è¡¨ç¤º
        else:
            st.write("Please enter a question and your answer.")  # ã‚¯ã‚¨ãƒªã¨è§£ç­”ã®å…¥åŠ›ã‚’ä¿ƒã™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º

# ãƒ¡ã‚¤ãƒ³é–¢æ•°
def main():
    init_page()  # ãƒšãƒ¼ã‚¸ã‚’åˆæœŸåŒ–
    selection = st.sidebar.radio("Go to", ["PDF Upload", "Study Questions"])  # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§ãƒšãƒ¼ã‚¸ã‚’é¸æŠ
    if selection == "PDF Upload":
        page_pdf_upload_and_build_vector_db()  # PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
    elif selection == "Study Questions":
        page_ask_my_pdf()  # å•é¡Œå‡ºé¡Œãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
    costs = st.session_state.get('costs', [])  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰ã‚³ã‚¹ãƒˆã‚’å–å¾—
    st.sidebar.markdown("## Costs")  # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚³ã‚¹ãƒˆã®ãƒ©ãƒ™ãƒ«ã‚’è¡¨ç¤º
    st.sidebar.markdown(f"**Total cost: ${sum(costs):.5f}**")  # åˆè¨ˆã‚³ã‚¹ãƒˆã‚’è¡¨ç¤º
    for cost in costs:
        st.sidebar.markdown(f"- ${cost:.5f}")  # å„ã‚³ã‚¹ãƒˆã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¡¨ç¤º

if __name__ == '__main__':
    main()  # ãƒ¡ã‚¤ãƒ³é–¢æ•°ã‚’å®Ÿè¡Œ

