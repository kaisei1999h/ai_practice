import streamlit as st
import pdfplumber
import random
from langchain.chat_models import ChatOpenAI

# ãƒšãƒ¼ã‚¸ã®åˆæœŸåŒ–
def init_page():
    st.set_page_config(page_title="å­¦ç¿’ãƒ˜ãƒ«ãƒ‘ãƒ¼", page_icon="ğŸ“˜")
    st.title("PDF å­¦ç¿’æ”¯æ´ (GPT-4)")

# GPT-4ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
def initialize_model():
    return ChatOpenAI(temperature=0, model_name="gpt-4o")

# PDF ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
def get_pdf_text(uploaded_file):
    with pdfplumber.open(uploaded_file) as pdf:
        return "\n".join(page.extract_text() for page in pdf.pages)

# PDFã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«ä¸€éƒ¨ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_random_text_sample(pdf_text, length=1000):
    start = random.randint(0, max(0, len(pdf_text) - length))
    return pdf_text[start:start + length]

# GPTã«å•é¡Œä½œæˆã‚’ä¾é ¼ã™ã‚‹é–¢æ•°
def generate_question_with_gpt(llm, pdf_text, question_type):
    text_sample = get_random_text_sample(pdf_text)
    prompt = f"""ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã®å†…å®¹ã«åŸºã¥ã„ã¦ã€{question_type}ã®ä¸€å•ä¸€ç­”å½¢å¼ã®å•é¡Œã‚’1ã¤ä½œæˆã—ã¦ãã ã•ã„ã€‚
    å•é¡Œã¯ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã‚“ã§ãã ã•ã„ã€‚å‰å›ã¨åŒã˜å•é¡Œã«ãªã‚‰ãªã„ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚ã‚ãªãŸã¯å­¦æ ¡ã®å…ˆç”Ÿã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ã¯æ—¥æœ¬ã®ä¸­å­¦ç”Ÿã§ã™ã€‚
    ç­”ãˆã¯åˆ¥é€”å‡ºåŠ›ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯å•é¡Œæ–‡ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

    ãƒ†ã‚­ã‚¹ãƒˆ:
    {text_sample}

    å•é¡Œã‚’å‡ºé¡Œã—ã¦ãã ã•ã„ã€‚
    """
    return llm.predict(prompt)

def check_answer_with_gpt(llm, conversation, user_answer):
    prompt = f"""ä»¥ä¸‹ã®ä¼šè©±ã®ç¶šãã¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ã«å¯¾ã™ã‚‹æ­£èª¤åˆ¤å®šã¨è©³ç´°ãªè§£èª¬ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
    
    ã“ã‚Œã¾ã§ã®ä¼šè©±:
    {conversation}

    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”: {user_answer}

    æ­£èª¤åˆ¤å®šã¨è§£èª¬:
    """
    return llm.predict(prompt)

def generate_next_question(llm, conversation, pdf_text, question_type):
    text_sample = get_random_text_sample(pdf_text)
    prompt = f"""ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã®å†…å®¹ã«åŸºã¥ã„ã¦ã€{question_type}ã®ä¸€å•ä¸€ç­”å½¢å¼ã®å•é¡Œã‚’1ã¤ä½œæˆã—ã¦ãã ã•ã„ã€‚
    å•é¡Œã¯ä¸€å•ã®ã¿ä½œæˆã—ã¦ãã ã•ã„ã€‚è¤‡æ•°ç­”ãˆã•ã›ã‚‹å•é¡Œã¯ä½œæˆã—ãªã„ã§ãã ã•ã„ã€‚å›ç­”ã¯ä¸€ã¤ã®ã¿ã«ã—ã¦ãã ã•ã„ã€‚
    å•é¡Œã¯ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã‚“ã§ãã ã•ã„ã€‚å‰å›ã¨åŒã˜,ä¼¼ãŸã‚ˆã†ãªå•é¡Œã«ãªã‚‰ãªã„ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
    ç­”ãˆã¯åˆ¥é€”å‡ºåŠ›ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯å•é¡Œæ–‡ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ã‚ãªãŸã¯å­¦æ ¡ã®å…ˆç”Ÿã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ã¯æ—¥æœ¬ã®ä¸­å­¦ç”Ÿã§ã™ã€‚
    ã“ã‚Œã¾ã§ã®ä¼šè©±:
    {conversation}
    
    å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ:
    {text_sample}
    
    å•é¡Œã®ã‚¿ã‚¤ãƒ—: {question_type}
    
    æ–°ã—ã„å•é¡Œã‚’å‡ºé¡Œã—ã¦ãã ã•ã„ã€‚
    """
    return llm.predict(prompt)


def main():
    if 'initialized' not in st.session_state:
        st.session_state.initialized = True
        st.session_state.question_number = 1
        st.session_state.conversation = ""
        st.session_state.current_question = ""
        st.session_state.waiting_for_answer = False
        st.session_state.user_answer = ""
    init_page()
    llm = initialize_model()

    if 'conversation' not in st.session_state:
        st.session_state.conversation = ""
    if 'current_question' not in st.session_state:
        st.session_state.current_question = ""
    if 'waiting_for_answer' not in st.session_state:
        st.session_state.waiting_for_answer = False
    if 'user_answer' not in st.session_state:
        st.session_state.user_answer = ""
    if 'pdf_text' not in st.session_state:
        st.session_state.pdf_text = ""
    if 'question_type' not in st.session_state:
        st.session_state.question_type = ""

    uploaded_file = st.file_uploader("å‹‰å¼·ç”¨PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ğŸ“š", type='pdf')
    if uploaded_file:
        with st.spinner("PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºä¸­..."):
            st.session_state.pdf_text = get_pdf_text(uploaded_file)
        st.success("PDFã®æŠ½å‡ºãŒå®Œäº†ã—ã¾ã—ãŸï¼")

    st.session_state.question_type = st.text_input("ã©ã®ã‚ˆã†ãªå•é¡Œã‚’å‡ºã—ã¦ã»ã—ã„ã§ã™ã‹ï¼Ÿï¼ˆä¾‹ï¼šå˜èªã®æ„å‘³ã‚’å•ã†ã€æ–‡æ³•ã«ã¤ã„ã¦è³ªå•ã™ã‚‹ï¼‰", value=st.session_state.question_type)
    
    if st.session_state.pdf_text and st.session_state.question_type and not st.session_state.current_question:
        st.session_state.current_question = generate_question_with_gpt(llm, st.session_state.pdf_text, st.session_state.question_type)
        st.session_state.conversation += f"\nè³ªå•: {st.session_state.current_question}"
        st.session_state.waiting_for_answer = True

    if st.session_state.current_question:
        st.write(st.session_state.current_question)

    if st.session_state.waiting_for_answer:
        user_answer = st.text_input("ã‚ãªãŸã®å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", key="answer_input", value="")
        if user_answer:
            st.session_state.conversation += f"\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”: {user_answer}"
            feedback = check_answer_with_gpt(llm, st.session_state.conversation, user_answer)
            st.write("è©•ä¾¡çµæœ:")
            st.write(feedback)
            st.session_state.conversation += f"\nè©•ä¾¡: {feedback}"
            st.session_state.waiting_for_answer = False
            st.session_state.user_answer = user_answer

    if not st.session_state.waiting_for_answer and st.session_state.current_question:
        if st.button("æ¬¡ã®å•é¡Œã¸é€²ã‚€"):
            st.session_state.current_question = generate_next_question(llm, st.session_state.conversation, st.session_state.pdf_text, st.session_state.question_type)
            st.session_state.conversation += f"\nè³ªå•: {st.session_state.current_question}"
            st.session_state.waiting_for_answer = True
            st.session_state.user_answer = ""
            st.experimental_rerun()

    # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ã®è¿½åŠ 
    if st.button("å­¦ç¿’ã‚’ãƒªã‚»ãƒƒãƒˆ"):
        # PDF ãƒ‡ãƒ¼ã‚¿ã®ã¿ä¿æŒ
        pdf_text = st.session_state.pdf_text
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        for key in list(st.session_state.keys()):
            if key != 'pdf_text':
                del st.session_state[key]
        
        # ä¿æŒã—ãŸPDFãƒ‡ãƒ¼ã‚¿ã‚’å†è¨­å®š
        st.session_state.pdf_text = pdf_text
        
        st.success("å­¦ç¿’ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã—ãŸã€‚æ–°ã—ã„å•é¡Œã‚¿ã‚¤ãƒ—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.experimental_rerun()

    st.write("ç¾åœ¨ã®ä¼šè©±å±¥æ­´:")
    st.write(st.session_state.conversation)

if __name__ == '__main__':
    main()